# ğŸ¯ Model EÄŸitim Stratejisi: Regularization + Data Augmentation

## ğŸ“š AÃ§Ä±klamalar

### 1. Regularization (DÃ¼zenleme) Nedir?

**Sorun:** Model veriyi ezberleyebilir (overfitting)

**Ã‡Ã¶zÃ¼m:** Regularization modelin kompleksliÄŸini sÄ±nÄ±rlar

**NasÄ±l Ã‡alÄ±ÅŸÄ±r:**
- Daha az aÄŸaÃ§ kullanÄ±r (n_estimators: 50 â†’ 30)
- Daha sÄ±ÄŸ aÄŸaÃ§lar (max_depth: 5 â†’ 3)
- Daha fazla Ã¶rnek gerektirir (min_samples_split: 5 â†’ 10)
- Her aÄŸaÃ§ sadece %80 Ã¶rnek kullanÄ±r (subsample=0.8)
- Sadece feature'larÄ±n bir kÄ±smÄ±nÄ± kullanÄ±r (max_features='sqrt')

**SonuÃ§:**
- âœ… Model daha genel kurallar Ã¶ÄŸrenir
- âœ… Ezberleme azalÄ±r
- âš ï¸ Performans biraz dÃ¼ÅŸebilir (ama daha gÃ¼venilir)

---

### 2. Data Augmentation (Veri Ã‡oÄŸaltma) Nedir?

**Sorun:** Az veri var (104 Ã¶rnek)

**Ã‡Ã¶zÃ¼m:** Mevcut veriyi Ã§oÄŸaltarak veri setini geniÅŸlet

**NasÄ±l Ã‡alÄ±ÅŸÄ±r:**
- Her feature'a kÃ¼Ã§Ã¼k rastgele noise eklenir (%5-10)
- Yeni Ã¶rnekler oluÅŸturulur ama "gerÃ§ekÃ§i" kalÄ±r
- Orijinal veri korunur, sadece yeni Ã¶rnekler eklenir

**Ã–rnek:**
```
Orijinal: player_avg_x = 940.5
Augmented: player_avg_x = 940.5 + (rastgele Â±5%) = 945.2
```

**SonuÃ§:**
- âœ… Daha fazla Ã¶rnek = daha iyi Ã¶ÄŸrenme
- âœ… Model farklÄ± varyasyonlarÄ± gÃ¶rÃ¼r
- âœ… Daha robust model

---

## ğŸ”¬ Ä°kisini Birlikte Kullanmak

### Neden MantÄ±klÄ±?

1. **Data Augmentation:** Daha fazla veri saÄŸlar
2. **Regularization:** Fazla komplekslikten korur
3. **Birlikte:** Hem daha fazla veri, hem daha gÃ¼venilir model

### Strateji

```
1. Orijinal veri (104 Ã¶rnek)
   â†“
2. Data Augmentation (104 â†’ ~208 Ã¶rnek)
   â†“
3. Regularized Model EÄŸitimi
   â†“
4. Daha iyi genelleÅŸtirme!
```

---

## ğŸ“Š Beklenen SonuÃ§lar

### Senaryo 1: Sadece Regularization
- âœ… Ezberleme azalÄ±r
- âš ï¸ Performans biraz dÃ¼ÅŸer (az veri yeterli deÄŸil)

### Senaryo 2: Sadece Data Augmentation  
- âœ… Daha fazla veri
- âš ï¸ Model hala ezberleyebilir (kompleks model)

### Senaryo 3: Ä°kisi Birlikte (Ã–NERÄ°LEN) â­
- âœ… Daha fazla veri (augmentation)
- âœ… Ezberleme azalÄ±r (regularization)
- âœ… Daha gÃ¼venilir ve robust model
- âœ… Test accuracy'de iyileÅŸme beklenir

---

## ğŸš€ KullanÄ±m

### AdÄ±m 1: Data Augmentation
```bash
python tools/augment_features.py --factor 1.0 --noise 0.05
```

### AdÄ±m 2: Regularized Model EÄŸitimi
```bash
python tools/train_model_regularized.py --features data/dataset/features_augmented.json
```

### AdÄ±m 3: KarÅŸÄ±laÅŸtÄ±rma
```bash
python tools/check_overfitting.py --model data/models/event_classifier_regularized.pkl
```

---

## âš™ï¸ Parametreler

### Augmentation Parametreleri

- `--factor 1.0`: Her Ã¶rnek iÃ§in 1 yeni Ã¶rnek (2x veri)
- `--factor 2.0`: Her Ã¶rnek iÃ§in 2 yeni Ã¶rnek (3x veri)
- `--noise 0.05`: %5 deÄŸiÅŸiklik (hafif)
- `--noise 0.10`: %10 deÄŸiÅŸiklik (daha fazla Ã§eÅŸitlilik)

**Ã–neri:** `--factor 1.0 --noise 0.05` ile baÅŸla, sonuÃ§lara gÃ¶re ayarla

### Regularization Parametreleri

- `n_estimators=30`: Daha az aÄŸaÃ§
- `max_depth=3`: Daha sÄ±ÄŸ aÄŸaÃ§lar
- `min_samples_split=10`: Daha fazla Ã¶rnek gerektirir
- `subsample=0.8`: Her aÄŸaÃ§ %80 Ã¶rnek kullanÄ±r

---

## ğŸ“ˆ SonuÃ§ Analizi

KarÅŸÄ±laÅŸtÄ±rÄ±lacak metrikler:

1. **Test Accuracy:** Hedef: %90+ (korunmalÄ± veya artmalÄ±)
2. **Train-Test FarkÄ±:** Hedef: <%5 (ezberleme azalmalÄ±)
3. **Cross-Validation:** Hedef: Test'e yakÄ±n (tutarlÄ±lÄ±k)

BaÅŸarÄ± kriterleri:
- âœ… Test accuracy korunuyor veya artÄ±yor
- âœ… Train-test farkÄ± azalÄ±yor (<%5)
- âœ… Model daha gÃ¼venilir hale geliyor



